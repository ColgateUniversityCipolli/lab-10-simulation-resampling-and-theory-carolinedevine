\documentclass{article}
\usepackage{amsmath} %This allows me to use the align functionality.
                     %If you find yourself trying to replicate
                     %something you found online, ensure you're
                     %loading the necessary packages!
\usepackage{amsfonts}%Math font
\usepackage{graphicx}%For including graphics
\usepackage{hyperref}%For Hyperlinks
\usepackage[shortlabels]{enumitem}% For enumerated lists with labels specified
                                  % We had to run tlmgr_install("enumitem") in R
\hypersetup{colorlinks = true,citecolor=black} %set citations to have black (not green) color
\usepackage{natbib}        %For the bibliography
\setlength{\bibsep}{0pt plus 0.3ex}
\bibliographystyle{apalike}%For the bibliography
\usepackage[margin=0.50in]{geometry}
\usepackage{float}
\usepackage{multicol}

%fix for figures
\usepackage{caption}
\newenvironment{Figure}
  {\par\medskip\noindent\minipage{\linewidth}}
  {\endminipage\par\medskip}
\begin{document}

\vspace{-1in}
\title{Lab 10 -- MATH 240 -- Computational Statistics}

\author{
  Caroline Devine \\
  Colgate University  \\
  Mathematics Department  \\
  {\tt cdevine@colgate.edu}
}

\date{04/08/2025}

\maketitle

\begin{multicols}{2}
%\raggedcolumns % If your spacing gets messed up try uncommenting 
                % this line
\begin{abstract}
This document provides a basic template for the 2-page labs we will complete each week. Here, briefly summarize what you did and why it might be helpful. Provide all the top-line conclusions, but avoid providing \emph{all} the details. Results should be limited to ``we show X, Y, and Z."
\end{abstract}

\noindent \textbf{Keywords:} What topics does the lab cover concerning class? List 3-4 key terms here, separated by semicolons.

\section{Introduction}

Gallup published a document called \emph{``How are Polls Conducted?"}. It outlines how Gallup selects people to include in its poll as well as other details. Focusing on two excerpts describing sample sizes of 1,000 and then 2,000, Gallup highlights how the results are accurate within a certain margin of error (\(\pm 4\% \) for n = 1000 and \(\pm 2\% \) for n = 2000). This margin of error tells researchers how much they can expect the sample proportion to differentiate from the proportion for the entire population. The goal of statisticians and quantitative researchers is to report a margin of error that provides 95\% confidence meaning they are 95\% confident that if they were to conduct the poll repeatably, they would contain the actual proportion 95\% of the time on the interval. The goal of this lab is to explore how sample size affects the margin of error as well as how to estimate this accurately. 

\section{Methods}
We will explore different simulations of different sample sizes and look at the differences in margins of errors through various mediums. To do this, we will look at basic simulation, resampling, simulations over different sample sizes and proportions, and calculate the actual margin of error. 

\subsection{Part 1: Basic Simulations}
Initially, we conducted a basic simulation study assuming a true probability that someone is satisfied with the position of United States in the world today to use the binomal distribution which measures the number of successes in a fixed number of trials. This was done using \texttt{rbinom()} function in \texttt{R}. We started with a sample size of 1,004 to replicate Gallup's example and doubled it for the second simulation completed. The sample proportion of the satisfied participants for each simulated poll was computed and plotted to visualize the distribution for both simulations. We also estimated the margin of error through calculation of the range of middle 95\% for comparison to Gallup's results. 

\subsection{Part 2: Resampling}

We assumed a true population proportion \emph{p} in part 1 which allowed us to see how the polls look like under that assumption, but in reality, we do not always know the true population proportion. To remove this assumption, we preform resampling to approximate the sampling distribution of \(\hat{p}\) using the Gallup survey data. This data reported that 39\% of respondents were satisfied with the position of the US in the world today, 59\% were dissatisfied, and 2\% had no opinion. These were categorized into ``satisfied", ``unsatisfied", and ``no opinion" categories for analysis, with the focus on estimating the proportion of respondents who were ``satisfied". Using the same sample size (n = 1004), we preformed 1,000 resamples and plotted them on a histogram with a superimposed density curve for visualization purposes. Margin of error was also calculated for comparison. 

\subsection{Part 3: Simulation over n and p}

To further explore how sample size(n) and the true population proportion(p) affects the margin of error, we simulated 10,000 simulations of a combination of increasing sample sizes and proportions. This is similar to the simulations in part 1, but at a larger scale. For each case, we calculated the margin of error using half of the range between the 2.5th and 97.5th percentiles of the sampling distribution. Using \texttt{geom\_raster()} function in \texttt{R} which produces a heatmap, we plotted the margin of error estimates across different values of n and p to visually see how population proportion and sample size affects margin of error.

\subsection{Part 4: Actual Margin of Error Calculation}

Estimating the margin of error from simulations is strong, but we can also find the actual margin of error through derivations of the Central Limit Theorem to find the Wilson Estimate analytically. The Wilson Estimate is a weighted average between \(\hat{P} = \frac{X}{n}\) and \(\frac{1}{2}\) where the weights are n and \(Z^2\) respectively. This provides an approximation of the margin of error called the Wilson margin of error formula:
$$
z_{1 - \alpha/2} * \frac{ \sqrt{n \hat{p} (1 - \hat{p}) + \frac{z_{1 - \alpha/2}^2}{4}} }{n + z_{1 - \alpha/2}^2}
$$
We computed the Wilson margin of error using the same values from part 3 for n and p and calculated z to be 1.96 using the standard normal distribution for a 95\% confidence interval. The table of errors were plotted them using a heatmap for comparison purposes. We did not need to use simulations for this step.

%% CODE FOR PLOTTING IN RESULTS AND APPENDIX %%
 <<echo=FALSE, eval=TRUE, results="asis", message=FALSE, warning=FALSE, size='scriptsize'>>=
 
################################################################################
# Part 1: Basic Simulation
################################################################################
library(tidyverse)
library(patchwork)
library(nleqslv)
library(xtable)

# True Probability
true.p <- 0.39

### First Sample Size ###
sample.size <- 1004
polls <- 10000

satisfied <- rbinom(polls, size = sample.size, prob = true.p)
proportion.satisfied <- satisfied/sample.size

og.sample <- tibble(proportion = proportion.satisfied)

# Range of the middle 95%
quant.nums <- quantile(proportion.satisfied, probs = c(0.025, 0.975))
range.middle <- quant.nums[2] - quant.nums[1]
margin.error <- range.middle/2
# This margin of error is approximately 3% which is lower than the 4% Gallup reported


### Second Sample Size ###
sample.size2 <- 2008 # doubled sample size

satisfied2 <- rbinom(polls, size = sample.size2, prob = true.p)
proportion.satisfied2 <- satisfied2/sample.size2

sample2 <- tibble(proportion = proportion.satisfied2)

# Range of the middle 95%
quant.nums.2 <- quantile(proportion.satisfied2, probs = c(0.025, 0.975))
range.middle.2 <- quant.nums.2[2] - quant.nums.2[1]
margin.error.2 <- range.middle.2/2
# This margin of error is approximately 2.15% which is slightly higher than the 2% Gallup reported

# Table
table1 <- tibble(
  `Sample Size` = c(1004, 2008),
  `Range of middle 95%` = c(range.middle, range.middle.2), 
  `Margin of Error` = c(margin.error, margin.error.2)
)
table.1 <- xtable(table1,
                   caption = "Margin of Error by Sample Size", 
                   label = "Table 1")  


################################################################################
# Part 2: Resampling
################################################################################

# Data from the Gallup Survey
samp.size <- 1004
perc.satisfied <- 0.39
perc.unsatisfied <- 0.59
perc.no.opinion <- 0.02 # is this relevant for the data

dat.gallup <- tibble(id = 1:samp.size,
                     response =  c(rep("satisfied", round(perc.satisfied*samp.size)),
                                   rep("unsatisfied", round(perc.unsatisfied*samp.size)),
                                   rep("no opinion", round(perc.no.opinion*samp.size)))
                    )

R <- 1000 # number of resamples
resamples <- tibble(p.hat = numeric(R))
for (i in 1:R){
  curr.resample <- sample(x = dat.gallup$response,
                          size = nrow(dat.gallup),
                          replace = TRUE)
  resamples$p.hat[i] <- mean(curr.resample == "satisfied")
}

re.quant <- quantile(resamples$p.hat, probs = c(0.025, 0.975))
re.range.middle <- re.quant[2] - re.quant[1]
re.margin.error <- re.range.middle / 2

# Table for Resamples
table2 <- tibble(
  `Sample Size` = 1004,
  `Range of middle 95%` = re.range.middle, 
  `Margin of Error` = re.margin.error
)
table.2 <- xtable(table2,
                   caption = "Margin of Error with Resampling", 
                   label = "Table 2")  
@

\section{Results}
\subsection{Basic Simulations}
The basic simulation study's goal was to examine how different sample sizes affects the sampling distribution and thus, the margin of error. Figure \ref{plot1} shows the visual representation of the sampling distrbutions and their density curves. Both appear to be approximately symmetric and bell-shaped. For \texttt{n = 1004}, the distribution is a relatively normal distribution is centered around 0.39. For \texttt{n = 2008}, the distribution has less variability because the spread of the sample proportions is more concentrated. Table \ref{table.1} corresponds to the graphical conclusions showing the margin of error decreasing as sample size increasings, aligning with Gallup's reported margins of error for each sample size. 
<<echo=FALSE, eval=TRUE, results="asis">>=
print(table.1,
      table.placement = "H", 
      include.rownames = FALSE, 
      size = "small", 
      caption.placement = "bottom")
@

\subsection{Resampling}
The 1,000 resamples of the same sample sizes using Gallup's reported survey data to approximate the sampling distribution of the sample propotion resulted in a margin of error around (\(\pm 2.93\% \). The range of the middle 95\% can be seen in Table \ref{table.2}. The margin of error and the shape of the distribution (Figure \ref{plot2}) approximately matches the basic simulation. This reinforces the reliability of Gallup's estimate, but shows there are slight differences. Due to the limited data from Gallup, we were only able to resample with one sample size, meaning we could not double the sample size as we did in the basic simulation. Ultiamtely, this shows that resampling is an efficient tool to estimate sampling distributions and variability when the true population proportion is unknown, which in reality, is typically accurate.
<<echo=FALSE, eval=TRUE, results="asis">>=
print(table.2,
      table.placement = "H", 
      include.rownames = FALSE, 
      size = "small", 
      caption.placement = "bottom")
@

\subsection{Simulations and Wilson Estimate}
As we increased the sample size (n) and the true population proportion(p), the results of the simulated trials showed that larger sample sizes do reduce the margin of error as seen in the left plot of Figure \ref{plot3}. The darker colors represent low margins of errors and the lighter ones reflect higher margins of errors. Although, the margin of error does not soley depend on the sample size; it also depends on p. Figure \ref{plot3} shows that when p is close to 0 or 1, the margin of error is smaller due to the limitations of the parameter space. This reflects higher variability when the population proportions are close to 50\% and sample sizes are small. This adds a missed refinement to  Gallup's story.
The actual margin of error calculation, shown in the right plot of Figure \ref{plot3}, reflects similar results across all n and p combinations. The Wilson formula, used to generate the actual margin of error calculation, allows for an analytical check to the simulation approach. The results of both the simulation and analyitcal approach align strongly, with small variations in the simulation approach which can be accounted by sampling error. 
These results highlight how both simulations and analyziation approaches are accurate, with the Wilson formula method providng more efficient results. 

\section{Discussion}
By analyzing how different approaches through basic simulation, resampling, simulation, and analytical evalutation, we are able to see how different sample sizes and population proportions affect the margin of error. This is extremmely important for statisticans and quantitative researchers for ensuring that the information they are reporting is accurate. The overall takeaway shows that Gallup is correct that larger sample sizes reduce the margin of error, but missed that the margin of error is also sensitive to the value of the population proportion. 


 You should objectively evaluate the evidence you found in the data. Do not embellish or wish-terpet (my made-up phase for making an interpretation you, or the researcher, wants to be true without the data \emph{actually} supporting it). Connect your findings to the existing information you provided in the Introduction.

Finally, provide some concluding remarks that tie together the entire paper. Think of the last part of the results as abstract-like. Tell the reader what they just consumed -- what's the takeaway message?

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Bibliography
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vspace{2em}

\noindent\textbf{Bibliography:} Note that when you add citations to your bib.bib file \emph{and}
you cite them in your document, the bibliography section will automatically populate here.

\begin{tiny}
\bibliography{bib}
\end{tiny}
\end{multicols}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Appendix
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\onecolumn
\section{Appendix}

<<plot1, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, size='scriptsize'>>=
sample.plot.1 <- ggplot(data = og.sample) + 
  geom_histogram(aes(x=proportion, y=after_stat(density)),
                 binwidth = 0.005,
                 color="grey")+
  geom_density(aes(x = proportion), color = "red")+
  geom_hline(yintercept=0)+
  theme_bw()+
  xlab("Sample Proportions")+
  ylab("Density")+
  ggtitle("Sampling Distribution (n = 1,004)")

#Shape is roughly normal (bell-shaped), centering around 0.39, symmetrical (small variation from random samping)
# Expected b/c of CLT 

sample.plot.2 <- ggplot(data = sample2) + 
  geom_histogram(aes(x=proportion, y=after_stat(density)),
                 binwidth = 0.005,
                 color="grey")+
  geom_density(aes(x = proportion), color = "red")+
  geom_hline(yintercept=0)+
  theme_bw()+
  xlab("Sample Proportions")+
  ylab("Density")+
  ggtitle("Sampling Distribution (n = 2,008)")

#Shape is roughly normal (bell-shaped), centering around 0.39, symmetrical (small variation from random samping)
# Expected b/c of CLT

# Two Samples Together
sample.distributions <- sample.plot.1 + sample.plot.2

@
\begin{figure}[H]
\begin{center}
<<echo=FALSE, warning=FALSE, message=FALSE, fig.dim=c(7,4), fig.align='center'>>=
sample.distributions
@
\caption{Sampling Distributions}
\label{plot1} 
\end{center}
\end{figure}

<<plot2, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, size='scriptsize'>>=
resample.plot <- ggplot(resamples) + 
  geom_histogram(aes(x=p.hat, y=after_stat(density)),
                      bins = 30,
                      color="grey")+
  geom_density(aes(x = p.hat), color = "red")+
  geom_hline(yintercept=0)+
  theme_bw()+
  xlab(bquote(hat(p)))+
  ylab("Density")+
  ggtitle("Resampling Distribution of "~hat(p))
@
\begin{figure}[H]
\begin{center}
<<echo=FALSE, warning=FALSE, message=FALSE, fig.dim=c(7,4), fig.align='center'>>=
resample.plot
@
\caption{Resampling Distributions}
\label{plot2} 
\end{center}
\end{figure}


<<plot3, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE, size='scriptsize'>>=
################################################################################
# Part 3: Simulation over n and p
################################################################################
nvalues <- seq(100, 3000, by = 10)
pvalues <- seq(0.01, 0.99, by = 0.01)
polls <- 10000 # 10,000 simulations

new.results <- tibble(n = numeric(),
                      p = numeric(),
                      moe = numeric())

for (n in nvalues){
  for (p in pvalues){
    sample.proportions <- rbinom(polls, size = n, prob = p)/n
    quant <- quantile(sample.proportions, probs = c(0.025, 0.975))
    moe <- (quant[2]-quant[1])/2
    
    new.results <- bind_rows(new.results,
                             tibble(n = n, 
                                    p = p, 
                                    moe = moe))
  }
}
view(new.results)

estimated.plot <- ggplot()+
  geom_raster(data = new.results, 
              aes(x = n, y = p, fill = moe))+
  scale_fill_viridis_c(name = "Margin of Error")+
  theme_bw()+
  labs(
    title = "Estimated Margin of Error as a Function of n and p",
    x = "Sample Size (n)",
    y = "True Proportion (p)"
  )

################################################################################
# Part 4: Actual Margin of Error Calculation
################################################################################

# Compute Wilson Margin of Error
nvalues <- seq(100, 3000, by = 10)
pvalues <- seq(0.01, 0.99, by = 0.01)
?qnorm
z <- qnorm(0.975) # z sub 1-alpha-2

wilson.results <- tibble(n = numeric(),
                         p = numeric(),
                         moe2 = numeric())

for (n in nvalues){
  for (p in pvalues){
    moe2 <- (sqrt( n*p*(1-p) + (z^2/4)))/
           (n +z^2)
    wilson.results <- bind_rows(wilson.results,
                                tibble(n = n, 
                                       p = p, 
                                       moe2 = moe2))
  }
}
view(wilson.results)

wilson.plot <- ggplot()+
  geom_raster(data = wilson.results, 
              aes(x = n, y = p, fill = moe2))+
  scale_fill_viridis_c(name = "Margin of Error")+
  theme_bw()+
  labs(
    title = "Wilson Margin of Error as a Function of n and p",
    x = "Sample Size (n)",
    y = "True Proportion (p)"
  )


## Comparison of geom_raster() plots
library(patchwork)
compared <- estimated.plot / wilson.plot 

# Wilson margin of error is a lot smaller that the estimated margin of error 
# when sample size is small (both are still dependent on p)
@
\begin{figure}[H]
\begin{center}
<<echo=FALSE, warning=FALSE, message=FALSE, fig.dim=c(11,8.5), fig.align='center'>>=
compared
@
\caption{Heatmap: Margin of Error Comparisons}
\label{plot3} 
\end{center}
\end{figure}


\end{document}